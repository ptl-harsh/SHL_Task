{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OINdwcDhpH_7GygZNk-iocEwTZqOvtsw",
      "authorship_tag": "ABX9TyP9jDBQNroJFsMTYlYdrIQW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptl-harsh/SHL_Task/blob/main/SHL_Hiring_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🗣️ Grammar Scoring System for Spoken Audio"
      ],
      "metadata": {
        "id": "yyoG8og5jpvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Install Required Libraries"
      ],
      "metadata": {
        "id": "8lAWAwGmkFiw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyIoVLR0SLxB",
        "outputId": "3c5a3112-f445-4caf-97dc-5e16b3e10e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa\n",
        "!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Modules and Set Global Variables"
      ],
      "metadata": {
        "id": "LKoF5XwZkHXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "import zipfile\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define directories (adjust if needed)\n",
        "TRAIN_AUDIO_DIR = '/content/drive/MyDrive/Datasets/SHL_Task/dataset/audios_train'\n",
        "TEST_AUDIO_DIR = '/content/drive/MyDrive/Datasets/SHL_Task/dataset/audios_test'\n"
      ],
      "metadata": {
        "id": "52D6GDgqd-ei"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xrUGKuxTkPeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c5cklipevIW",
        "outputId": "5f7bbf84-9910-4272-a3b6-98de169046c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CSV Files"
      ],
      "metadata": {
        "id": "cPhdlJx_kSih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Datasets/SHL_Task/dataset/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Datasets/SHL_Task/dataset/test.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/Datasets/SHL_Task/dataset/sample_submission.csv')\n",
        "\n",
        "print(\"Training samples:\", train_df.shape[0])\n",
        "print(\"Test samples:\", test_df.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3KiqCByehL4",
        "outputId": "87e427c6-c80b-4729-feea-8d830292ec60"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 444\n",
            "Test samples: 195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Feature Extraction Function"
      ],
      "metadata": {
        "id": "w6ryl6HfkVQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_path, sr=22050, n_mfcc=13):\n",
        "    \"\"\"\n",
        "    Load an audio file and extract mean and std of MFCC features.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=sr)\n",
        "        # Compute MFCC features\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        # Take mean and standard deviation of MFCC coefficients\n",
        "        mfccs_mean = np.mean(mfccs, axis=1)\n",
        "        mfccs_std = np.std(mfccs, axis=1)\n",
        "        features = np.concatenate([mfccs_mean, mfccs_std])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        features = np.zeros(n_mfcc * 2)\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "bQQJZGnQekB7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Features from Training Data"
      ],
      "metadata": {
        "id": "_D6Pi4FbkWtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "print(\"Extracting features from training audio files...\")\n",
        "for idx, row in tqdm(train_df.iterrows(), total=train_df.shape[0]):\n",
        "    file_name = row['filename']\n",
        "    label = row['label']\n",
        "    file_path = os.path.join(TRAIN_AUDIO_DIR, file_name)\n",
        "    features = extract_features(file_path)\n",
        "    X_train.append(features)\n",
        "    y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(\"Extracted features shape (train):\", X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PixcVDD5enRQ",
        "outputId": "e4e857c3-de7f-406c-9d38-d9b9c8233d74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from training audio files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 444/444 [04:33<00:00,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features shape (train): (444, 26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Features from Test Data"
      ],
      "metadata": {
        "id": "SZYgoIHYka5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "test_files = []\n",
        "print(\"Extracting features from test audio files...\")\n",
        "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
        "    file_name = row['filename']\n",
        "    file_path = os.path.join(TEST_AUDIO_DIR, file_name)\n",
        "    features = extract_features(file_path)\n",
        "    X_test.append(features)\n",
        "    test_files.append(file_name)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "print(\"Extracted features shape (test):\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izNpWP9wfTsn",
        "outputId": "3673ba67-524e-4171-bfe1-0b5fa63d95a2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from test audio files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [02:01<00:00,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features shape (test): (195, 26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Custom Pearson Correlation Scorer"
      ],
      "metadata": {
        "id": "vA_3YC6xkdtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pearson_corr(y_true, y_pred):\n",
        "    return pearsonr(y_true, y_pred)[0]\n",
        "\n",
        "pearson_scorer = make_scorer(pearson_corr, greater_is_better=True)\n"
      ],
      "metadata": {
        "id": "2grbEaxCgwhY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model with Cross-Validation"
      ],
      "metadata": {
        "id": "USCs2QJvkg2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a RandomForestRegressor (feel free to experiment with other models)\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Perform cross-validation (using KFold)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=pearson_scorer)\n",
        "print(\"Cross-Validation Pearson Correlation scores:\", cv_scores)\n",
        "print(\"Mean CV Pearson Correlation:\", np.mean(cv_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmFzJAHdhbOs",
        "outputId": "71965950-dbe7-402e-eb00-6b7dc3757444"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Pearson Correlation scores: [0.50930532 0.58693964 0.70354799 0.59908329 0.59337028]\n",
            "Mean CV Pearson Correlation: 0.5984493048725888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on Full Data and Make Predictions"
      ],
      "metadata": {
        "id": "IwZO57HFkjMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the full training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Q2fNQau1hdDS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Submission File"
      ],
      "metadata": {
        "id": "UooLKShakl3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    'filename': test_files,\n",
        "    'label': predictions\n",
        "})\n",
        "submission = submission.sort_values('filename')  # Adjust ordering if needed\n",
        "\n",
        "submission_csv = 'submission.csv'\n",
        "submission.to_csv(submission_csv, index=False)\n",
        "print(f\"Submission file saved as {submission_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Zoskr1hhdn",
        "outputId": "f295a2ac-2fe5-4e53-9962-d03aa8969705"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved as submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "scfczJWGhl63"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sJXtWJZmhq38"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}